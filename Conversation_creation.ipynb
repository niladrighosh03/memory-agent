{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_cell",
   "metadata": {},
   "source": [
    "# Conversation Generation with Persuasion Strategies\n",
    "\n",
    "This notebook generates realistic insurance sales conversations where each agent utterance is annotated with one of 5 persuasion strategies:\n",
    "- **logical**: Facts, data, comparisons, cost-benefit analysis\n",
    "- **emotional**: Fears, peace of mind, security, past trauma\n",
    "- **credibility**: Expert opinions, certifications, industry standards\n",
    "- **personalization**: Tailored advice to specific customer profile\n",
    "- **social_proof**: What similar customers do, popular choices, testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eef78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_prompt(persona_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate the prompt for conversation creation with persuasion strategy annotations.\n",
    "    \n",
    "    Args:\n",
    "        persona_json: JSON string representation of the customer persona\n",
    "        \n",
    "    Returns:\n",
    "        Formatted prompt string for the LLM\n",
    "    \"\"\"\n",
    "    conversation_prompt = f\"\"\"\n",
    "You are an expert conversational AI agent for insurance sales and advisory.\n",
    "\n",
    "You will be provided with a CUSTOMER PERSONA in JSON format.\n",
    "Your task is to generate a realistic, long-horizon conversation between a user and an insurance agent based strictly on that persona.\n",
    "\n",
    "The goal is to simulate how an agent would gradually guide the customer toward clarity and trust using different persuasion strategies.\n",
    "\n",
    "----------------\n",
    "GOAL OF THE CONVERSATION\n",
    "----------------\n",
    "Based on the information available in the persona:\n",
    "- Reflect the customer's concerns, motivations, and past experiences\n",
    "- Adapt the agent's responses to the customer's preferences and psychology\n",
    "- Progress naturally over multiple turns\n",
    "- Gradually converge toward an appropriate insurance recommendation\n",
    "\n",
    "----------------\n",
    "PERSUASION STRATEGIES\n",
    "----------------\n",
    "Each AGENT utterance must be annotated with EXACTLY ONE persuasion strategy from the list below:\n",
    "\n",
    "- logical: Use facts, data, comparisons, cost-benefit analysis\n",
    "- emotional: Address fears, peace of mind, security, past trauma\n",
    "- credibility: Cite expert opinions, certifications, industry standards, trusted sources\n",
    "- personalization: Tailor advice to specific customer profile, preferences, and situation\n",
    "- social_proof: Reference what similar customers do, popular choices, testimonials\n",
    "\n",
    "User utterances must NOT be annotated.\n",
    "\n",
    "Do not repeat the same persuasion strategy in consecutive agent turns.\n",
    "\n",
    "----------------\n",
    "CONVERSATION RULES\n",
    "----------------\n",
    "- The conversation must be fully grounded in the given persona\n",
    "- Do not invent traits that contradict the persona\n",
    "- User messages should reflect the persona's mindset and concerns\n",
    "- Agent messages should respect the customer's communication and decision style\n",
    "- The tone should be natural, calm, and professional\n",
    "- The conversation should feel realistic and human, not scripted\n",
    "\n",
    "----------------\n",
    "OUTPUT FORMAT\n",
    "----------------\n",
    "The output must be STRICTLY valid JSON and follow this exact structure:\n",
    "\n",
    "{{\n",
    "  \"conversation_id\": \"C_017_2022\",\n",
    "  \"turns\": [\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"...\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"...\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "----------------\n",
    "EXAMPLE CONVERSATION (FORMAT REFERENCE ONLY)\n",
    "----------------\n",
    "{{\n",
    "  \"conversation_id\": \"C_017_2022\",\n",
    "  \"turns\": [\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"My renewal premium went up again this year. I'm thinking of switching.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"That makes sense. Since cost is an important factor for you, I'll focus on plans that reduce your premium without removing essential coverage.\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I just don't want another headache if I have to file a claim.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"I understand that concern, especially given your past experience. This option is known for smoother claim processing and faster approvals.\",\n",
    "      \"persuasion_strategy\": \"emotional\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"Okay, but I don't want a lot of extras.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Based on your city driving needs, I'll recommend a single plan with only roadside assistance and windshield cover to keep things simple and cost-effective.\",\n",
    "      \"persuasion_strategy\": \"personalization\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "----------------\n",
    "STRUCTURE REQUIREMENTS\n",
    "----------------\n",
    "- Generate 8 to 14 total turns\n",
    "- conversation_id must be unique\n",
    "- Maintain a logical progression across turns\n",
    "- Ensure internal consistency with the persona\n",
    "- Do not include markdown, explanations, or extra text\n",
    "\n",
    "----------------\n",
    "TASK\n",
    "----------------\n",
    "Using the CUSTOMER PERSONA provided below, generate ONE complete conversation in the exact JSON format shown.\n",
    "\n",
    "CUSTOMER PERSONA:\n",
    "{persona_json}\n",
    "\n",
    "Now generate the conversation.\n",
    "\"\"\"\n",
    "    return conversation_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f83f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 12:53:51.876464: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 12:53:51.890378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-26 12:53:51.907059: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-26 12:53:51.912000: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-26 12:53:51.924447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-26 12:53:53.070785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03d2dadaedd4d1e866a1c438e840760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244acae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate(tokenizer, model, prompt: str, max_tokens: int = 2048):\n",
    "    \"\"\"Generate text using the LLM.\"\"\"\n",
    "    messages = f\"<s>[INST] {prompt} [/INST]\"\n",
    "\n",
    "    inputs = tokenizer(messages, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    generated_ids = outputs[0][inputs.input_ids.shape[1]:]\n",
    "    return tokenizer.decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "json_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "def extract_json_from_response(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract JSON from LLM response that may contain markdown or extra text.\n",
    "    \n",
    "    Args:\n",
    "        raw_output: Raw LLM response\n",
    "        \n",
    "    Returns:\n",
    "        Extracted JSON string\n",
    "    \"\"\"\n",
    "    # Try to find JSON between code blocks\n",
    "    json_match = re.search(r'```(?:json)?\\s*({.*?})\\s*```', raw_output, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1)\n",
    "    \n",
    "    # Try to find JSON directly\n",
    "    json_match = re.search(r'({\\s*\"conversation_id\".*})', raw_output, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1)\n",
    "    \n",
    "    # Return original if no pattern matches\n",
    "    return raw_output.strip()\n",
    "\n",
    "\n",
    "def validate_conversation(conversation: Dict) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Validate the conversation structure and persuasion strategy annotations.\n",
    "    \n",
    "    Args:\n",
    "        conversation: Parsed conversation JSON\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    valid_strategies = {\"logical\", \"emotional\", \"credibility\", \"personalization\", \"social_proof\"}\n",
    "    \n",
    "    # Check required fields\n",
    "    if \"conversation_id\" not in conversation:\n",
    "        return False, \"Missing 'conversation_id'\"\n",
    "    \n",
    "    if \"turns\" not in conversation:\n",
    "        return False, \"Missing 'turns'\"\n",
    "    \n",
    "    turns = conversation[\"turns\"]\n",
    "    if not isinstance(turns, list):\n",
    "        return False, \"'turns' must be a list\"\n",
    "    \n",
    "    if len(turns) < 8 or len(turns) > 14:\n",
    "        return False, f\"Conversation must have 8-14 turns, got {len(turns)}\"\n",
    "    \n",
    "    # Validate each turn\n",
    "    prev_strategy = None\n",
    "    for i, turn in enumerate(turns):\n",
    "        if \"speaker\" not in turn:\n",
    "            return False, f\"Turn {i} missing 'speaker'\"\n",
    "        \n",
    "        if \"utterance\" not in turn:\n",
    "            return False, f\"Turn {i} missing 'utterance'\"\n",
    "        \n",
    "        speaker = turn[\"speaker\"]\n",
    "        if speaker not in [\"user\", \"agent\"]:\n",
    "            return False, f\"Turn {i} has invalid speaker: {speaker}\"\n",
    "        \n",
    "        # Agent turns must have persuasion_strategy\n",
    "        if speaker == \"agent\":\n",
    "            if \"persuasion_strategy\" not in turn:\n",
    "                return False, f\"Agent turn {i} missing 'persuasion_strategy'\"\n",
    "            \n",
    "            strategy = turn[\"persuasion_strategy\"]\n",
    "            if strategy not in valid_strategies:\n",
    "                return False, f\"Turn {i} has invalid strategy: {strategy}\"\n",
    "            \n",
    "            # Check for consecutive same strategies\n",
    "            if prev_strategy and strategy == prev_strategy:\n",
    "                return False, f\"Consecutive agent turns {i-1} and {i} use same strategy: {strategy}\"\n",
    "            \n",
    "            prev_strategy = strategy\n",
    "        else:\n",
    "            # User turns should not have persuasion_strategy\n",
    "            if \"persuasion_strategy\" in turn:\n",
    "                return False, f\"User turn {i} should not have 'persuasion_strategy'\"\n",
    "            prev_strategy = None  # Reset for proper consecutive check\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "\n",
    "def get_next_conversation_id(output_dir: str = \"conversations\") -> str:\n",
    "    \"\"\"\n",
    "    Generate the next conversation ID based on existing files.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing conversation files\n",
    "        \n",
    "    Returns:\n",
    "        Next conversation ID (e.g., \"C_001\")\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    max_id = 0\n",
    "    for file_path in output_dir.glob(\"C_*.json\"):\n",
    "        match = re.search(r\"C_(\\d+)\", file_path.name)\n",
    "        if match:\n",
    "            num = int(match.group(1))\n",
    "            if num > max_id:\n",
    "                max_id = num\n",
    "    \n",
    "    return f\"C_{max_id + 1:03d}\"\n",
    "\n",
    "\n",
    "def save_conversation_json(raw_output: str, output_dir: str = \"conversations\") -> Tuple[Path, Dict]:\n",
    "    \"\"\"\n",
    "    Parse, validate, and save a conversation JSON.\n",
    "    \n",
    "    Args:\n",
    "        raw_output: Raw LLM output\n",
    "        output_dir: Directory to save conversations\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (file_path, conversation_dict)\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract and parse JSON\n",
    "    json_str = extract_json_from_response(raw_output)\n",
    "    conversation = json.loads(json_str)\n",
    "    \n",
    "    # Validate conversation\n",
    "    is_valid, error_msg = validate_conversation(conversation)\n",
    "    if not is_valid:\n",
    "        raise ValueError(f\"Invalid conversation: {error_msg}\")\n",
    "    \n",
    "    conversation_id = conversation[\"conversation_id\"]\n",
    "    file_path = output_dir / f\"{conversation_id}.json\"\n",
    "    \n",
    "    if file_path.exists():\n",
    "        raise FileExistsError(\n",
    "            f\"Conversation {conversation_id} already exists. Use a different ID.\"\n",
    "        )\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(conversation, f, indent=2)\n",
    "    \n",
    "    return file_path, conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conversation_generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_from_persona(\n",
    "    persona_path: str,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    output_dir: str = \"conversations\",\n",
    "    max_retries: int = 3\n",
    ") -> Tuple[Path, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a conversation from a persona file.\n",
    "    \n",
    "    Args:\n",
    "        persona_path: Path to persona JSON file\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        model: HuggingFace model\n",
    "        output_dir: Directory to save conversations\n",
    "        max_retries: Maximum number of retries on validation failure\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (file_path, conversation_dict)\n",
    "    \"\"\"\n",
    "    # Load persona\n",
    "    with open(persona_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        persona = json.load(f)\n",
    "    \n",
    "    persona_json = json.dumps(persona, indent=2)\n",
    "    prompt = conversation_prompt(persona_json)\n",
    "    \n",
    "    # Generate with retries\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Generating conversation (attempt {attempt + 1}/{max_retries})...\")\n",
    "            raw_output = llm_generate(tokenizer, model, prompt, max_tokens=2048)\n",
    "            \n",
    "            file_path, conversation = save_conversation_json(raw_output, output_dir)\n",
    "            print(f\"✓ Conversation saved: {file_path}\")\n",
    "            return file_path, conversation\n",
    "            \n",
    "        except (json.JSONDecodeError, ValueError, KeyError) as e:\n",
    "            print(f\"✗ Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"\\nFailed output:\\n{raw_output}\\n\")\n",
    "                raise\n",
    "    \n",
    "    raise RuntimeError(\"Failed to generate valid conversation after all retries\")\n",
    "\n",
    "\n",
    "def analyze_conversation_stats(conversation: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze statistics of a conversation.\n",
    "    \n",
    "    Args:\n",
    "        conversation: Conversation dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of statistics\n",
    "    \"\"\"\n",
    "    turns = conversation[\"turns\"]\n",
    "    \n",
    "    strategy_counts = {}\n",
    "    user_turns = 0\n",
    "    agent_turns = 0\n",
    "    \n",
    "    for turn in turns:\n",
    "        if turn[\"speaker\"] == \"user\":\n",
    "            user_turns += 1\n",
    "        else:\n",
    "            agent_turns += 1\n",
    "            strategy = turn.get(\"persuasion_strategy\")\n",
    "            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        \"total_turns\": len(turns),\n",
    "        \"user_turns\": user_turns,\n",
    "        \"agent_turns\": agent_turns,\n",
    "        \"strategy_distribution\": strategy_counts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "batch_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generate_conversations(\n",
    "    persona_dir: str = \"personas\",\n",
    "    output_dir: str = \"conversations\",\n",
    "    max_personas: Optional[int] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate conversations for all personas in a directory.\n",
    "    \n",
    "    Args:\n",
    "        persona_dir: Directory containing persona JSON files\n",
    "        output_dir: Directory to save conversations\n",
    "        max_personas: Maximum number of personas to process (None for all)\n",
    "    \"\"\"\n",
    "    persona_dir = Path(persona_dir)\n",
    "    persona_files = sorted(persona_dir.glob(\"P_*.json\"))\n",
    "    \n",
    "    if max_personas:\n",
    "        persona_files = persona_files[:max_personas]\n",
    "    \n",
    "    print(f\"Found {len(persona_files)} persona(s) to process\\n\")\n",
    "    \n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, persona_path in enumerate(persona_files, 1):\n",
    "        print(f\"\\n[{i}/{len(persona_files)}] Processing: {persona_path.name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            file_path, conversation = generate_conversation_from_persona(\n",
    "                str(persona_path),\n",
    "                tokenizer,\n",
    "                model,\n",
    "                output_dir\n",
    "            )\n",
    "            \n",
    "            stats = analyze_conversation_stats(conversation)\n",
    "            print(f\"\\nStats:\")\n",
    "            print(f\"  Total turns: {stats['total_turns']}\")\n",
    "            print(f\"  Strategy distribution: {stats['strategy_distribution']}\")\n",
    "            \n",
    "            results.append({\n",
    "                \"persona\": persona_path.name,\n",
    "                \"conversation\": file_path.name,\n",
    "                \"stats\": stats\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ ERROR: {e}\")\n",
    "            errors.append({\n",
    "                \"persona\": persona_path.name,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Successfully generated: {len(results)}\")\n",
    "    print(f\"Failed: {len(errors)}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"\\nErrors:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error['persona']}: {error['error']}\")\n",
    "    \n",
    "    return results, errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage_examples",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### Example 1: Generate a single conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate conversation for a single persona\n",
    "persona_path = \"personas/P_001.json\"\n",
    "\n",
    "file_path, conversation = generate_conversation_from_persona(\n",
    "    persona_path,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    output_dir=\"conversations\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated conversation: {file_path}\")\n",
    "print(f\"Conversation ID: {conversation['conversation_id']}\")\n",
    "print(f\"Number of turns: {len(conversation['turns'])}\")\n",
    "\n",
    "# Display conversation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONVERSATION\")\n",
    "print(\"=\" * 60)\n",
    "for i, turn in enumerate(conversation['turns'], 1):\n",
    "    speaker = turn['speaker'].upper()\n",
    "    utterance = turn['utterance']\n",
    "    strategy = turn.get('persuasion_strategy', '')\n",
    "    \n",
    "    print(f\"\\n[Turn {i}] {speaker}\")\n",
    "    if strategy:\n",
    "        print(f\"Strategy: {strategy}\")\n",
    "    print(f\"{utterance}\")\n",
    "\n",
    "# Display statistics\n",
    "stats = analyze_conversation_stats(conversation)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(stats, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_example",
   "metadata": {},
   "source": [
    "### Example 2: Batch generate conversations for all personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "example_batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 persona(s) to process\n",
      "\n",
      "\n",
      "[1/7] Processing: P_001.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✗ ERROR: Conversation C_018_2022 already exists. Use a different ID.\n",
      "\n",
      "[2/7] Processing: P_002.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✗ Attempt 1 failed: Invalid conversation: Turn 5 has invalid strategy: personalization, emotional\n",
      "Generating conversation (attempt 2/3)...\n",
      "✗ Attempt 2 failed: Invalid conversation: Turn 7 has invalid strategy: information_format\n",
      "Generating conversation (attempt 3/3)...\n",
      "✗ Attempt 3 failed: Invalid conversation: Turn 11 has invalid strategy: multiple_options\n",
      "\n",
      "Failed output:\n",
      "{\n",
      "  \"conversation_id\": \"C_022_2022\",\n",
      "  \"turns\": [\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"I'm looking for car insurance for the first time.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"Great! As a first-time buyer, I'll guide you through the process while keeping your budget in consideration.\",\n",
      "      \"persuasion_strategy\": \"personalization\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"What coverage should I get? I don't want to pay for things I don't need.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"Given your minimum coverage goal, I recommend focusing on essential third-party liability and personal accident coverage.\",\n",
      "      \"persuasion_strategy\": \"personalization\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"But what about other damages?\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"That's a concern, and I understand you want peace of mind. Let me share some data: third-party liability covers damages to others' property, while personal accident coverage protects you and your family.\",\n",
      "      \"persuasion_strategy\": \"logical\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"Alright, but I don't want a high deductible.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"I hear you. Let me suggest a plan with a low deductible that fits your budget.\",\n",
      "      \"persuasion_strategy\": \"credibility\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"What about communication? I'd like detailed information.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"Your preferred communication style is detailed, so I'll ensure all the information I provide will be clear and comprehensive.\",\n",
      "      \"persuasion_strategy\": \"personalization\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"user\",\n",
      "      \"utterance\": \"I want to understand my options before making a decision.\"\n",
      "    },\n",
      "    {\n",
      "      \"speaker\": \"agent\",\n",
      "      \"utterance\": \"Absolutely. Let's explore the various choices that meet your needs and budget, so you can make an informed decision.\",\n",
      "      \"persuasion_strategy\": \"multiple_options\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "✗ ERROR: Invalid conversation: Turn 11 has invalid strategy: multiple_options\n",
      "\n",
      "[3/7] Processing: P_003.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "\n",
      "✗ ERROR: Conversation C_003_2022 already exists. Use a different ID.\n",
      "\n",
      "[4/7] Processing: P_004.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_004_2022.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 14\n",
      "  Strategy distribution: {'personalization': 3, 'logical': 2, 'emotional': 1, 'credibility': 1}\n",
      "\n",
      "[5/7] Processing: P_005.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_005_2022.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 12\n",
      "  Strategy distribution: {'logical': 2, 'personalization': 2, 'emotional': 1, 'credibility': 1}\n",
      "\n",
      "[6/7] Processing: P_006.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_006_2022.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 12\n",
      "  Strategy distribution: {'personalization': 3, 'emotional': 1, 'logical': 2}\n",
      "\n",
      "[7/7] Processing: P_007.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_007_2022.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 12\n",
      "  Strategy distribution: {'personalization': 3, 'social_proof': 1, 'emotional': 1, 'logical': 1}\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Successfully generated: 4\n",
      "Failed: 3\n",
      "\n",
      "Errors:\n",
      "  - P_001.json: Conversation C_018_2022 already exists. Use a different ID.\n",
      "  - P_002.json: Invalid conversation: Turn 11 has invalid strategy: multiple_options\n",
      "  - P_003.json: Conversation C_003_2022 already exists. Use a different ID.\n"
     ]
    }
   ],
   "source": [
    "# Generate conversations for all personas\n",
    "results, errors = batch_generate_conversations(\n",
    "    persona_dir=\"personas\",\n",
    "    output_dir=\"conversations\",\n",
    "    max_personas=7  # Set to a number to limit, e.g., 5 for testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_example",
   "metadata": {},
   "source": [
    "### Example 3: Validate an existing conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_validate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate an existing conversation\n",
    "conversation_path = \"conversations/C_001.json\"\n",
    "\n",
    "with open(conversation_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    conversation = json.load(f)\n",
    "\n",
    "is_valid, error_msg = validate_conversation(conversation)\n",
    "\n",
    "if is_valid:\n",
    "    print(f\"✓ Conversation is valid!\")\n",
    "    stats = analyze_conversation_stats(conversation)\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(json.dumps(stats, indent=2))\n",
    "else:\n",
    "    print(f\"✗ Validation failed: {error_msg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
