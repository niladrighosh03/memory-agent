{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_cell",
   "metadata": {},
   "source": [
    "# Conversation Generation with Persuasion Strategies\n",
    "\n",
    "This notebook generates realistic insurance sales conversations where each agent utterance is annotated with one of 5 persuasion strategies:\n",
    "- **logical**: Facts, data, comparisons, cost-benefit analysis\n",
    "- **emotional**: Fears, peace of mind, security, past trauma\n",
    "- **credibility**: Expert opinions, certifications, industry standards\n",
    "- **personalization**: Tailored advice to specific customer profile\n",
    "- **social_proof**: What similar customers do, popular choices, testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22eef78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_prompt(persona_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate the prompt for conversation creation with persuasion strategy annotations.\n",
    "    \n",
    "    Args:\n",
    "        persona_json: JSON string representation of the customer persona\n",
    "        \n",
    "    Returns:\n",
    "        Formatted prompt string for the LLM\n",
    "    \"\"\"\n",
    "    conversation_prompt = f\"\"\"\n",
    "You are an expert conversational AI agent for insurance sales and advisory.\n",
    "\n",
    "You will be provided with a CUSTOMER PERSONA in JSON format.\n",
    "Your task is to generate a realistic, long-horizon conversation between a user and an insurance agent based strictly on that persona.\n",
    "\n",
    "The goal is to simulate how an agent would gradually guide the customer toward clarity and trust using different persuasion strategies.\n",
    "\n",
    "----------------\n",
    "GOAL OF THE CONVERSATION\n",
    "----------------\n",
    "Based on the information available in the persona:\n",
    "- Reflect the customer's concerns, motivations, and past experiences\n",
    "- Adapt the agent's responses to the customer's preferences and psychology\n",
    "- Progress naturally over multiple turns\n",
    "- Gradually converge toward an appropriate insurance recommendation\n",
    "\n",
    "----------------\n",
    "PERSUASION STRATEGIES\n",
    "----------------\n",
    "Each AGENT utterance must be annotated with EXACTLY ONE persuasion strategy from the list below:\n",
    "\n",
    "- logical: Use facts, data, comparisons, cost-benefit analysis\n",
    "- emotional: Address fears, peace of mind, security, past trauma\n",
    "- credibility: Cite expert opinions, certifications, industry standards, trusted sources\n",
    "- personalization: Tailor advice to specific customer profile, preferences, and situation\n",
    "- social_proof: Reference what similar customers do, popular choices, testimonials\n",
    "\n",
    "User utterances must NOT be annotated.\n",
    "\n",
    "Do not repeat the same persuasion strategy in consecutive agent turns.\n",
    "\n",
    "----------------\n",
    "CONVERSATION RULES\n",
    "----------------\n",
    "- The conversation must be fully grounded in the given persona\n",
    "- Do not invent traits that contradict the persona\n",
    "- User messages should reflect the persona's mindset and concerns\n",
    "- Agent messages should respect the customer's communication and decision style\n",
    "- The tone should be natural, calm, and professional\n",
    "- The conversation should feel realistic and human, not scripted\n",
    "\n",
    "----------------\n",
    "OUTPUT FORMAT\n",
    "----------------\n",
    "The output must be STRICTLY valid JSON and follow this exact structure:\n",
    "\n",
    "{{\n",
    "  \"conversation_id\": \"C_017_2022\",\n",
    "  \"turns\": [\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"...\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"...\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "----------------\n",
    "EXAMPLE CONVERSATION (FORMAT REFERENCE ONLY)\n",
    "----------------\n",
    "{{\n",
    "  \"conversation_id\": \"C_017_2022\",\n",
    "  \"turns\": [\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"My renewal premium went up again this year. I'm thinking of switching.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"That makes sense. Since cost is an important factor for you, I'll focus on plans that reduce your premium without removing essential coverage.\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I just don't want another headache if I have to file a claim.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"I understand that concern, especially given how stressful claims can feel. This option is known for smoother claim processing and faster approvals.\",\n",
    "      \"persuasion_strategy\": \"emotional\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"Okay, but I don't want a lot of extras.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Based on your city driving needs, I'll recommend a single plan with only roadside assistance and windshield cover to keep things simple and cost-effective.\",\n",
    "      \"persuasion_strategy\": \"personalization\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"How do I know this insurer is reliable?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"That's a fair question. This insurer has consistently maintained a high claim settlement ratio over the past several years.\",\n",
    "      \"persuasion_strategy\": \"credibility\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I’ve heard some companies delay payouts.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Many customers with similar policies have shared positive experiences, especially appreciating the quick turnaround during claims.\",\n",
    "      \"persuasion_strategy\": \"social_proof\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I drive mostly short distances. Does that really matter?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Yes, it does. Since your annual mileage is low, choosing a lower-risk profile helps reduce unnecessary premium costs.\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"What if something unexpected happens?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"That worry is completely natural. This plan still protects you from major financial shocks while avoiding over-insurance.\",\n",
    "      \"persuasion_strategy\": \"emotional\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I don't want to keep changing policies every year.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Given your preference for stability, this plan is designed with long-term renewability benefits and minimal premium jumps.\",\n",
    "      \"persuasion_strategy\": \"personalization\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"Are these benefits actually documented?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Yes, they are clearly stated in the policy wording and approved by regulatory authorities, ensuring transparency.\",\n",
    "      \"persuasion_strategy\": \"credibility\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"Have other people like me chosen this plan?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Absolutely. Many urban drivers with similar usage patterns have opted for this plan and renewed it without issues.\",\n",
    "      \"persuasion_strategy\": \"social_proof\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"What happens if I sell my car next year?\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"In that case, the policy allows easy transfer or cancellation, helping you avoid unnecessary financial loss.\",\n",
    "      \"persuasion_strategy\": \"logical\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"I just want peace of mind.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"That’s completely understandable. The goal here is to give you confidence that you’re protected without constant worry.\",\n",
    "      \"persuasion_strategy\": \"emotional\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"user\",\n",
    "      \"utterance\": \"Alright, this does sound reasonable.\"\n",
    "    }},\n",
    "    {{\n",
    "      \"speaker\": \"agent\",\n",
    "      \"utterance\": \"Based on everything you've shared, this option aligns well with your budget, driving habits, and desire for simplicity.\",\n",
    "      \"persuasion_strategy\": \"personalization\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "\n",
    "----------------\n",
    "STRUCTURE REQUIREMENTS\n",
    "----------------\n",
    "- Generate 20 to 30 total turns\n",
    "- conversation_id must be unique\n",
    "- Maintain a logical progression across turns\n",
    "- Ensure internal consistency with the persona\n",
    "- Do not include markdown, explanations, or extra text\n",
    "\n",
    "----------------\n",
    "TASK\n",
    "----------------\n",
    "Using the CUSTOMER PERSONA provided below, generate ONE complete conversation in the exact JSON format shown.\n",
    "\n",
    "CUSTOMER PERSONA:\n",
    "{persona_json}\n",
    "\n",
    "Now generate the conversation.\n",
    "\"\"\"\n",
    "    return conversation_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f83f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 12:13:09.211861: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-29 12:13:09.226276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-29 12:13:09.245712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-29 12:13:09.251368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-29 12:13:09.265919: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-29 12:13:12.352353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e525f7d3abf413e8079361178cc4f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244acae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate(tokenizer, model, prompt: str, max_tokens: int = 2048):\n",
    "    \"\"\"Generate text using the LLM.\"\"\"\n",
    "    messages = f\"<s>[INST] {prompt} [/INST]\"\n",
    "\n",
    "    inputs = tokenizer(messages, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    generated_ids = outputs[0][inputs.input_ids.shape[1]:]\n",
    "    return tokenizer.decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "json_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conversation_json(raw_output: str, persona_id: str, output_dir: str = \"conversations\") -> Tuple[Path, Dict]:\n",
    "    \"\"\"\n",
    "    Parse, validate, and save a conversation JSON.\n",
    "    Generates unique ID in format: C_{persona_id}_{counter}\n",
    "    \n",
    "    Args:\n",
    "        raw_output: Raw LLM output\n",
    "        persona_id: Persona ID (e.g., 'P_001')\n",
    "        output_dir: Directory to save conversations\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (file_path, conversation_dict)\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract and parse JSON\n",
    "    json_str = extract_json_from_response(raw_output)\n",
    "    conversation = json.loads(json_str)\n",
    "    \n",
    "    # Validate conversation\n",
    "    is_valid, error_msg = validate_conversation(conversation)\n",
    "    if not is_valid:\n",
    "        raise ValueError(f\"Invalid conversation: {error_msg}\")\n",
    "    \n",
    "    # Clean persona_id (remove underscores: P_001 -> P001)\n",
    "    clean_persona_id = persona_id.replace(\"_\", \"\")\n",
    "    \n",
    "    # Generate unique conversation ID based on persona and counter\n",
    "    # Format: C_{clean_persona_id}_{counter:03d} (e.g., C_P001_001, C_P001_002)\n",
    "    counter = 1\n",
    "    while True:\n",
    "        conversation_id = f\"C_{clean_persona_id}_{counter:03d}\"\n",
    "        file_path = output_dir / f\"{conversation_id}.json\"\n",
    "        if not file_path.exists():\n",
    "            break\n",
    "        counter += 1\n",
    "    \n",
    "    # Update conversation with generated ID\n",
    "    conversation[\"conversation_id\"] = conversation_id\n",
    "    \n",
    "    # Save the conversation\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(conversation, f, indent=2)\n",
    "    \n",
    "    return file_path, conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conversation_generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_from_persona(\n",
    "    persona_path: str,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    output_dir: str = \"conversations\",\n",
    "    max_retries: int = 3\n",
    ") -> Tuple[Path, Dict]:\n",
    "    \"\"\"\n",
    "    Generate a conversation from a persona file.\n",
    "    \n",
    "    Args:\n",
    "        persona_path: Path to persona JSON file\n",
    "        tokenizer: HuggingFace tokenizer\n",
    "        model: HuggingFace model\n",
    "        output_dir: Directory to save conversations\n",
    "        max_retries: Maximum number of retries on validation failure\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (file_path, conversation_dict)\n",
    "    \"\"\"\n",
    "    # Load persona\n",
    "    with open(persona_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        persona = json.load(f)\n",
    "    \n",
    "    # Extract persona_id\n",
    "    persona_id = persona.get(\"persona_id\", Path(persona_path).stem)\n",
    "    \n",
    "    persona_json = json.dumps(persona, indent=2)\n",
    "    prompt = conversation_prompt(persona_json)\n",
    "    \n",
    "    # Generate with retries\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Generating conversation (attempt {attempt + 1}/{max_retries})...\")\n",
    "            raw_output = llm_generate(tokenizer, model, prompt, max_tokens=3072)\n",
    "            \n",
    "            # Pass persona_id to save function\n",
    "            file_path, conversation = save_conversation_json(raw_output, persona_id, output_dir)\n",
    "            print(f\"✓ Conversation saved: {file_path}\")\n",
    "            return file_path, conversation\n",
    "            \n",
    "        except (json.JSONDecodeError, ValueError, KeyError) as e:\n",
    "            print(f\"✗ Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"\\nFailed output:\\n{raw_output}\\n\")\n",
    "                raise\n",
    "    \n",
    "    raise RuntimeError(\"Failed to generate valid conversation after all retries\")\n",
    "\n",
    "\n",
    "def analyze_conversation_stats(conversation: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze statistics of a conversation.\n",
    "    \n",
    "    Args:\n",
    "        conversation: Conversation dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of statistics\n",
    "    \"\"\"\n",
    "    turns = conversation[\"turns\"]\n",
    "    \n",
    "    strategy_counts = {}\n",
    "    user_turns = 0\n",
    "    agent_turns = 0\n",
    "    \n",
    "    for turn in turns:\n",
    "        if turn[\"speaker\"] == \"user\":\n",
    "            user_turns += 1\n",
    "        else:\n",
    "            agent_turns += 1\n",
    "            strategy = turn.get(\"persuasion_strategy\")\n",
    "            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        \"total_turns\": len(turns),\n",
    "        \"user_turns\": user_turns,\n",
    "        \"agent_turns\": agent_turns,\n",
    "        \"strategy_distribution\": strategy_counts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "batch_generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generate_conversations(\n",
    "    persona_dir: str = \"personas\",\n",
    "    output_dir: str = \"conversations\",\n",
    "    max_personas: Optional[int] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate conversations for all personas in a directory.\n",
    "    \n",
    "    Args:\n",
    "        persona_dir: Directory containing persona JSON files\n",
    "        output_dir: Directory to save conversations\n",
    "        max_personas: Maximum number of personas to process (None for all)\n",
    "    \"\"\"\n",
    "    persona_dir = Path(persona_dir)\n",
    "    persona_files = sorted(persona_dir.glob(\"P_*.json\"))\n",
    "    \n",
    "    if max_personas:\n",
    "        persona_files = persona_files[:max_personas]\n",
    "    \n",
    "    print(f\"Found {len(persona_files)} persona(s) to process\\n\")\n",
    "    \n",
    "    results = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, persona_path in enumerate(persona_files, 1):\n",
    "        print(f\"\\n[{i}/{len(persona_files)}] Processing: {persona_path.name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            file_path, conversation = generate_conversation_from_persona(\n",
    "                str(persona_path),\n",
    "                tokenizer,\n",
    "                model,\n",
    "                output_dir\n",
    "            )\n",
    "            \n",
    "            stats = analyze_conversation_stats(conversation)\n",
    "            print(f\"\\nStats:\")\n",
    "            print(f\"  Total turns: {stats['total_turns']}\")\n",
    "            print(f\"  Strategy distribution: {stats['strategy_distribution']}\")\n",
    "            \n",
    "            results.append({\n",
    "                \"persona\": persona_path.name,\n",
    "                \"conversation\": file_path.name,\n",
    "                \"stats\": stats\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ ERROR: {e}\")\n",
    "            errors.append({\n",
    "                \"persona\": persona_path.name,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Successfully generated: {len(results)}\")\n",
    "    print(f\"Failed: {len(errors)}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(\"\\nErrors:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error['persona']}: {error['error']}\")\n",
    "    \n",
    "    return results, errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage_examples",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### Example 1: Generate a single conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate conversation for a single persona\n",
    "persona_path = \"personas/P_001.json\"\n",
    "\n",
    "file_path, conversation = generate_conversation_from_persona(\n",
    "    persona_path,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    output_dir=\"conversations\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated conversation: {file_path}\")\n",
    "print(f\"Conversation ID: {conversation['conversation_id']}\")\n",
    "print(f\"Number of turns: {len(conversation['turns'])}\")\n",
    "\n",
    "# Display conversation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONVERSATION\")\n",
    "print(\"=\" * 60)\n",
    "for i, turn in enumerate(conversation['turns'], 1):\n",
    "    speaker = turn['speaker'].upper()\n",
    "    utterance = turn['utterance']\n",
    "    strategy = turn.get('persuasion_strategy', '')\n",
    "    \n",
    "    print(f\"\\n[Turn {i}] {speaker}\")\n",
    "    if strategy:\n",
    "        print(f\"Strategy: {strategy}\")\n",
    "    print(f\"{utterance}\")\n",
    "\n",
    "# Display statistics\n",
    "stats = analyze_conversation_stats(conversation)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(stats, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_example",
   "metadata": {},
   "source": [
    "### Example 2: Batch generate conversations for all personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "example_batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 persona(s) to process\n",
      "\n",
      "\n",
      "[1/5] Processing: P_001.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_P001_001.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 22\n",
      "  Strategy distribution: {'emotional': 2, 'logical': 5, 'personalization': 3, 'credibility': 1}\n",
      "\n",
      "[2/5] Processing: P_002.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_P002_001.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 22\n",
      "  Strategy distribution: {'personalization': 4, 'logical': 4, 'credibility': 1, 'emotional': 2}\n",
      "\n",
      "[3/5] Processing: P_003.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✓ Conversation saved: conversations/C_P003_001.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 26\n",
      "  Strategy distribution: {'personalization': 7, 'logical': 3, 'emotional': 2, 'credibility': 1}\n",
      "\n",
      "[4/5] Processing: P_004.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✗ Attempt 1 failed: Invalid conversation: Turn 21 has invalid strategy: multiple_options\n",
      "Generating conversation (attempt 2/3)...\n",
      "✓ Conversation saved: conversations/C_P004_001.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 24\n",
      "  Strategy distribution: {'personalization': 5, 'logical': 3, 'emotional': 1, 'credibility': 2, 'social_proof': 1}\n",
      "\n",
      "[5/5] Processing: P_005.json\n",
      "============================================================\n",
      "Generating conversation (attempt 1/3)...\n",
      "✗ Attempt 1 failed: Invalid conversation: Turn 1 has invalid strategy: customer_segment_profile\n",
      "Generating conversation (attempt 2/3)...\n",
      "✓ Conversation saved: conversations/C_P005_001.json\n",
      "\n",
      "Stats:\n",
      "  Total turns: 26\n",
      "  Strategy distribution: {'personalization': 6, 'logical': 4, 'emotional': 2, 'credibility': 1}\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Successfully generated: 5\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Generate conversations for all personas\n",
    "results, errors = batch_generate_conversations(\n",
    "    persona_dir=\"personas\",\n",
    "    output_dir=\"conversations\",\n",
    "    max_personas=5  # Set to a number to limit, e.g., 5 for testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_example",
   "metadata": {},
   "source": [
    "### Example 3: Validate an existing conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example_validate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and validate an existing conversation\n",
    "conversation_path = \"conversations/C_001.json\"\n",
    "\n",
    "with open(conversation_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    conversation = json.load(f)\n",
    "\n",
    "is_valid, error_msg = validate_conversation(conversation)\n",
    "\n",
    "if is_valid:\n",
    "    print(f\"✓ Conversation is valid!\")\n",
    "    stats = analyze_conversation_stats(conversation)\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(json.dumps(stats, indent=2))\n",
    "else:\n",
    "    print(f\"✗ Validation failed: {error_msg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
