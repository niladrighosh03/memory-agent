{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ecbcdc-1f4e-416a-befe-8c854df8898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 personas per archetype...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:08<00:00, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 10 personas to personas.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"XYZ\"\n",
    "\n",
    "# ---------- schema ----------\n",
    "\n",
    "class Driver(BaseModel):\n",
    "    role: str\n",
    "    age: int\n",
    "\n",
    "class DrivingUsage(BaseModel):\n",
    "    commute_distance_km: str\n",
    "    driving_environment: str\n",
    "    daily_parking: str\n",
    "    business_use: bool\n",
    "    annual_mileage_band: str\n",
    "    primary_drivers: List[Driver]\n",
    "\n",
    "class SegmentProfile(BaseModel):\n",
    "    price_sensitivity: str\n",
    "    buyer_type: str\n",
    "    switching_reason: str\n",
    "    claims_trauma: str\n",
    "\n",
    "class ServicePreferences(BaseModel):\n",
    "    communication_style: str\n",
    "    decision_style: str\n",
    "    information_format: str\n",
    "    preferred_channel: str\n",
    "\n",
    "class ProductPreferences(BaseModel):\n",
    "    coverage_goal: str\n",
    "    deductible_appetite: str\n",
    "    valued_addons: List[str]\n",
    "\n",
    "class Persona(BaseModel):\n",
    "    persona_id: str\n",
    "    archetype: str\n",
    "    driving_usage_profile: DrivingUsage\n",
    "    customer_segment_profile: SegmentProfile\n",
    "    service_preferences: ServicePreferences\n",
    "    product_preferences: ProductPreferences\n",
    "\n",
    "\n",
    "class PersonaList(BaseModel):\n",
    "    items: List[Persona]\n",
    "\n",
    "# ---------- model ----------\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\", \n",
    "    temperature=1.1,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(PersonaList)\n",
    "\n",
    "\n",
    "# ---------- archetypes ----------\n",
    "\n",
    "ARCHETYPES = [\n",
    "    \"Young urban professional\",\n",
    "    \"Student / early career youth\",\n",
    "    \"Family household with kids\",\n",
    "    \"Self-employed / small business owner\",\n",
    "    \"Gig worker / delivery driver\",\n",
    "    \"Corporate executive / high income owner\",\n",
    "    \"Homemaker / occasional driver\",\n",
    "    \"Senior citizen / retired\",\n",
    "    \"Rural or semi-urban resident\",\n",
    "    \"Budget-conscious daily commuter\"\n",
    "]\n",
    "\n",
    "\n",
    "# ---------- prompt ----------\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Generate realistic and diverse Indian motor insurance customer personas.\"),\n",
    "    (\"human\",\n",
    "     \"Generate exactly {n} personas for archetype: {arch}. \"\n",
    "     \"Fill all fields realistically and vary behavior.\")\n",
    "])\n",
    "\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "\n",
    "\n",
    "def generate_all(per_type=1, out_file=\"personas.json\"):\n",
    "    all_personas = []\n",
    "    pid = 1\n",
    "\n",
    "    print(f\"Generating {per_type} personas per archetype...\")\n",
    "\n",
    "    for arch in tqdm(ARCHETYPES):\n",
    "        try:\n",
    "             \n",
    "            result_wrapper = chain.invoke({\n",
    "                \"n\": per_type,\n",
    "                \"arch\": arch\n",
    "            })\n",
    "            \n",
    "          \n",
    "            personas = result_wrapper.items \n",
    "\n",
    "            for p in personas:\n",
    "                p.persona_id = f\"P_{pid:03d}\"\n",
    "                p.archetype = arch\n",
    "                all_personas.append(p.model_dump())\n",
    "                pid += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating {arch}: {e}\")\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(all_personas, f, indent=2)\n",
    "\n",
    "    print(f\"saved {len(all_personas)} personas to {out_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_all(per_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce102a0-bacc-443d-af26-7347c9e9f567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
